{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D://Project//NLP//dataset//train.csv',  usecols=['target', 'comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train- Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( train, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text): ### The function will take in text and lower case it remove the stopwords, symbols and return it\n",
    "    \n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "    text = text.lower()                     \n",
    "    text = re.compile('[/(){}\\[\\]\\|@,;]').sub(' ', text)    \n",
    "    text = re.compile('[^0-9a-z #+_]').sub('', text)\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(STOPWORDS) + r')\\b\\s*') \n",
    "    text = pattern.sub('', text)    \n",
    "    text = re.sub(' +', ' ', text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle missing Comments by unknown Value and Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\manis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\manis\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "COMMENT = 'comment_text'\n",
    "X_train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "X_test[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "X_train[COMMENT] = [text_prepare(COMMENT) for COMMENT in X_train[COMMENT]]\n",
    "X_test[COMMENT] = [text_prepare(COMMENT) for COMMENT in X_test[COMMENT]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Backup of the train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_up_train = X_train\n",
    "back_up_test = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF_IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(X_train, X_test):\n",
    "    vect_word = TfidfVectorizer(max_features=30000, lowercase=True, analyzer='word',stop_words= 'english',dtype=np.float32)\n",
    "    tr_vect = vect_word.fit_transform(X_train['comment_text'])\n",
    "    ts_vect = vect_word.transform(X_test['comment_text'])\n",
    "    X = sparse.hstack([tr_vect])\n",
    "    x_test = sparse.hstack([ts_vect])\n",
    "    return X, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, x_test = tf_idf(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Under- Sampling and Google word-to-vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_word_vec = gensim.models.KeyedVectors.load_word2vec_format(\"C:/Users/manis/Downloads/GoogleNews-vectors-negative300.bin.gz\", binary = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "more = 0\n",
    "less = 0\n",
    "y1 = list(y_train)\n",
    "for i in range(len(y_train)):\n",
    "    if ((y1)[i] >= 0.4):\n",
    "        more += 1\n",
    "    else:\n",
    "        less += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newy = []\n",
    "v = min(more, less)\n",
    "a = 0\n",
    "b = 0\n",
    "newx = []\n",
    "for i in range(len(y_train)):\n",
    "    if ((y1)[i] >= 0.4 and a < v):\n",
    "        a += 1\n",
    "        newx.append(X_train['comment_text'][i])\n",
    "        newy.append((y1)[i])\n",
    "    if (y1[i] < 0.4 and b < v):\n",
    "        b += 1\n",
    "        newx.append(X_train['comment_text'][i])\n",
    "        newy.append((y1)[i])\n",
    "    if (a == v and b == v):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToVec(sentences, google_word_vec):\n",
    "    \n",
    "    sent_vocab = []\n",
    "    c = 0\n",
    "    word2vect = google_word_vec.vocab.keys()  \n",
    "    for sentence in sentences:\n",
    "        if (c == -1):\n",
    "            break\n",
    "        word_vocab = []\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            if word in word2vect:\n",
    "                word_vocab.append( google_word_vec[word] )\n",
    "        word_vocab = np.mean( word_vocab, axis = 0 )\n",
    "#         print(c)\n",
    "#         if (c == 397):\n",
    "#             print(\"adfa\")\n",
    "        if (word_vocab.shape == ()):\n",
    "            word_vocab = [0]*300\n",
    "        sent_vocab.append(list(word_vocab))\n",
    "        c += 1\n",
    "    #data = [np.array( sent_vocab ), list(sentences)]\n",
    "    return (sent_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\manis\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "x_train_word = wordToVec(newx,google_word_vec) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_word = wordToVec(X_test['comment_text'],google_word_vec) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Under- Sampling and TF- IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_sampled(X_train, X_test):\n",
    "    vect_word = TfidfVectorizer(max_features=30000, lowercase=True, analyzer='word',stop_words= 'english', dtype = np.float32)\n",
    "    tr_vect = vect_word.fit_transform(X_train)\n",
    "    ts_vect = vect_word.transform(X_test['comment_text'])\n",
    "    X = sparse.hstack([tr_vect])\n",
    "    x_test = sparse.hstack([ts_vect])\n",
    "    return X, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf, x_test_tfidf = tf_idf_sampled(newx, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegression(X, y_train, x_test, y_test, filename):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X,y_train)\n",
    "    #cv_score.append(lr.score)\n",
    "    pred_linear = lr.predict(x_test)\n",
    "    print(\"Mean Square Error for Linear Regression is : \", mean_squared_error(y_test, pred_linear))\n",
    "    pickle.dump(lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lassoRegression(X, y_train, x_test, y_test,filename):\n",
    "    clf = linear_model.Lasso(alpha=0.1)\n",
    "    clf.fit(X,y_train)\n",
    "    pred_lasso = clf.predict(x_test)\n",
    "    print(\"Mean Square Error for Lasso Regression is : \", mean_squared_error(y_test, pred_lasso))\n",
    "    pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RidgeRegression(X, y_train, x_test, y_test,filename):\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(X,y_train)\n",
    "    pred_ridge = clf.predict(x_test)\n",
    "    print(\"Mean Square Error for Ridge Regression is : \",mean_squared_error(y_test, pred_ridge))\n",
    "    pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X, y_train, x_test, y_test,filename):\n",
    "    regr = RandomForestRegressor(max_depth=100, random_state=0,\n",
    "                             n_estimators=1000)\n",
    "    regr.fit(X, y_train)  \n",
    "\n",
    "    pred_randomforest = regr.predict(x_test)\n",
    "    print(\"Mean Square Error for Random Forest Regression is : \",mean_squared_error(y_test, pred_randomforest))\n",
    "    pickle.dump(regr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decisiontree(X, y_train, x_test, y_test,filename):\n",
    "    regr = DecisionTreeRegressor(max_depth=20, random_state=0)\n",
    "    regr.fit(X, y_train)  \n",
    "\n",
    "    pred_randomforest = regr.predict(x_test)\n",
    "    print(\"Mean Square Error for DecisionTree Regression is : \",mean_squared_error(y_test, pred_randomforest))\n",
    "    pickle.dump(regr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsampled Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error for Linear Regression is :  0.01871687792612595\n",
      "Mean Square Error for Lasso Regression is :  0.039165215832144995\n",
      "Mean Square Error for Ridge Regression is :  0.018140524093080788\n"
     ]
    }
   ],
   "source": [
    "linearRegression(X, y_train, x_test, y_test,\"linear_Regression_TF_IDF.model\")\n",
    "lassoRegression(X, y_train, x_test, y_test,\"lasso_Regression_TF_IDF.model\")\n",
    "RidgeRegression(X, y_train, x_test, y_test,\"Ridge_Regression_TF_IDF.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error for Linear Regression is :  0.042724580891998355\n",
      "Mean Square Error for Lasso Regression is :  0.0833801457354903\n",
      "Mean Square Error for Ridge Regression is :  0.03013191301251815\n"
     ]
    }
   ],
   "source": [
    "linearRegression(X_tfidf, newy, x_test_tfidf, y_test,\"linear_Regression_tfidf_sampled_.model\")\n",
    "lassoRegression(X_tfidf, newy, x_test_tfidf, y_test,\"lasso_Regression_tfidf_sampled.model\")\n",
    "RidgeRegression(X_tfidf, newy, x_test_tfidf, y_test,\"Ridge_Regression_tfidf_sampled.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error for Linear Regression is :  0.05304814974211168\n",
      "Mean Square Error for Lasso Regression is :  0.08338015363432451\n",
      "Mean Square Error for Ridge Regression is :  0.05304867256532046\n"
     ]
    }
   ],
   "source": [
    "linearRegression(x_train_word, newy, x_test_word, y_test,\"linear_Regression_Word_2_Vec.model\")\n",
    "lassoRegression(x_train_word, newy, x_test_word, y_test,\"lasso_Regression_Word_2_Vec.model\")\n",
    "RidgeRegression(x_train_word, newy, x_test_word, y_test,\"Ridge_Regression_Word_2_Vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Results for TF - IDF -  Without Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(X, y_train, x_test, y_test,\"RandomForest_Regression_TF_IDF.model\")\n",
    "Decisiontree(X, y_train, x_test, y_test,\"Decisiontree_Regression_TF_IDF.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Results for TF - IDF -  With Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(X_tfidf, newy, x_test_tfidf, y_test,\"RandomForest_Regression_tfidf_sampled.model\")\n",
    "Decisiontree(X, y_train, x_test, y_test,\"Decisiontree_Regression_TF_IDF_sampled.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Based Results for Word to Vec -  With Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest(x_train_word, newy, x_test_word, y_test,\"RandomForest_Regression_Word_2_Vec.model\")\n",
    "Decisiontree(x_train_word, newy, x_test_word, y_test,\"RandomForest_Regression_Word_2_Vec.model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
